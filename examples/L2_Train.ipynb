{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0% 0/2500 [00:06<?, ?it/s, lr=0.01, epoch=0, loss=0.352, fake_loss=0, real_loss=0.705]684]/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:113: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "Epoch 0:   0% 1/2500 [00:23<16:06:51, 23.21s/it, lr=0.01, epoch=0, loss=0.674, fake_loss=0.665, real_loss=0.684]/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:113: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "Epoch 0: 100% 2499/2500 [43:15<00:01,  1.04s/it, lr=0.00978, epoch=0, loss=0.575, fake_loss=0.58, real_loss=0.57]3]\n",
      "Epoch 0: 100% 2499/2500 [43:15<00:01,  1.04s/it, lr=0.00978, epoch=0, loss=0.574, fake_loss=0.576, real_loss=0.573]\n",
      "100%|███████████████████████████████████████| 9120/9120 [38:06<00:00,  3.99it/s]\n",
      "Epoch 1: 100% 2499/2500 [1:21:57<00:01,  1.97s/it, lr=0.00955, epoch=1, loss=0.422, fake_loss=0.429, real_loss=0.415]  \n",
      "Epoch 1: 100% 2499/2500 [43:01<00:01,  1.03s/it, lr=0.00955, epoch=1, loss=0.437, fake_loss=0.439, real_loss=0.435]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:55<00:00,  4.01it/s]\n",
      "Epoch 2: 100% 2499/2500 [1:21:47<00:01,  1.96s/it, lr=0.00933, epoch=2, loss=0.368, fake_loss=0.373, real_loss=0.362]   \n",
      "Epoch 2: 100% 2499/2500 [43:06<00:01,  1.04s/it, lr=0.00933, epoch=2, loss=0.378, fake_loss=0.391, real_loss=0.364]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:55<00:00,  4.01it/s]\n",
      "Epoch 3: 100% 2499/2500 [42:59<00:01,  1.03s/it, lr=0.0091, epoch=3, loss=0.328, fake_loss=0.341, real_loss=0.314]4]    \n",
      "Epoch 3: 100% 2499/2500 [1:21:35<00:01,  1.96s/it, lr=0.0091, epoch=3, loss=0.335, fake_loss=0.336, real_loss=0.334]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:57<00:00,  4.00it/s]\n",
      "Epoch 4: 100% 2499/2500 [42:59<00:01,  1.03s/it, lr=0.00887, epoch=4, loss=0.312, fake_loss=0.325, real_loss=0.3]05]   \n",
      "Epoch 4: 100% 2499/2500 [1:21:39<00:01,  1.96s/it, lr=0.00887, epoch=4, loss=0.312, fake_loss=0.32, real_loss=0.305]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:57<00:00,  4.00it/s]\n",
      "Epoch 5: 100% 2499/2500 [1:21:41<00:01,  1.96s/it, lr=0.00865, epoch=5, loss=0.293, fake_loss=0.294, real_loss=0.292]   \n",
      "Epoch 5: 100% 2499/2500 [42:58<00:01,  1.03s/it, lr=0.00865, epoch=5, loss=0.297, fake_loss=0.303, real_loss=0.292]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:53<00:00,  4.01it/s]\n",
      "Epoch 6: 100% 2499/2500 [42:58<00:01,  1.03s/it, lr=0.00842, epoch=6, loss=0.28, fake_loss=0.283, real_loss=0.276]7]   \n",
      "Epoch 6: 100% 2499/2500 [1:21:19<00:01,  1.95s/it, lr=0.00842, epoch=6, loss=0.28, fake_loss=0.292, real_loss=0.267]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:53<00:00,  4.01it/s]\n",
      "Epoch 7: 100% 2499/2500 [42:55<00:01,  1.03s/it, lr=0.00819, epoch=7, loss=0.274, fake_loss=0.287, real_loss=0.262]1]   \n",
      "Epoch 7: 100% 2499/2500 [1:21:34<00:01,  1.96s/it, lr=0.00819, epoch=7, loss=0.268, fake_loss=0.285, real_loss=0.251]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:53<00:00,  4.01it/s]\n",
      "Epoch 8: 100% 2499/2500 [42:56<00:01,  1.03s/it, lr=0.00796, epoch=8, loss=0.265, fake_loss=0.261, real_loss=0.27]43]    \n",
      "Epoch 8: 100% 2499/2500 [1:21:23<00:01,  1.95s/it, lr=0.00796, epoch=8, loss=0.268, fake_loss=0.292, real_loss=0.243]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:47<00:00,  4.02it/s]\n",
      "Epoch 9: 100% 2499/2500 [42:52<00:01,  1.03s/it, lr=0.00773, epoch=9, loss=0.249, fake_loss=0.261, real_loss=0.238]4]  \n",
      "\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:48<00:00,  4.02it/s]\n",
      "Epoch 10: 100% 2499/2500 [42:52<00:01,  1.03s/it, lr=0.0075, epoch=10, loss=0.252, fake_loss=0.26, real_loss=0.243]2]       \n",
      "Epoch 10: 100% 2499/2500 [1:21:25<00:01,  1.95s/it, lr=0.0075, epoch=10, loss=0.25, fake_loss=0.268, real_loss=0.232]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:45<00:00,  4.03it/s]\n",
      "Epoch 11: 100% 2499/2500 [1:21:12<00:01,  1.95s/it, lr=0.00727, epoch=11, loss=0.252, fake_loss=0.268, real_loss=0.236]    \n",
      "Epoch 11: 100% 2499/2500 [42:51<00:01,  1.03s/it, lr=0.00727, epoch=11, loss=0.248, fake_loss=0.254, real_loss=0.242]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:47<00:00,  4.02it/s]\n",
      "Epoch 12: 100% 2499/2500 [1:20:42<00:01,  1.94s/it, lr=0.00704, epoch=12, loss=0.243, fake_loss=0.246, real_loss=0.241]     \n",
      "Epoch 12: 100% 2499/2500 [42:25<00:01,  1.02s/it, lr=0.00704, epoch=12, loss=0.247, fake_loss=0.263, real_loss=0.232]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:43<00:00,  4.03it/s]\n",
      "Epoch 13: 100% 2499/2500 [1:20:32<00:01,  1.93s/it, lr=0.0068, epoch=13, loss=0.247, fake_loss=0.265, real_loss=0.229]      \n",
      "Epoch 13: 100% 2499/2500 [42:03<00:01,  1.01s/it, lr=0.0068, epoch=13, loss=0.248, fake_loss=0.254, real_loss=0.242]\n",
      "100%|███████████████████████████████████████| 9120/9120 [37:51<00:00,  4.01it/s]\n",
      "Epoch 14: 100% 2499/2500 [1:20:35<00:01,  1.93s/it, lr=0.00657, epoch=14, loss=0.25, fake_loss=0.263, real_loss=0.237]     \n",
      "Epoch 14: 100% 2499/2500 [42:11<00:01,  1.01s/it, lr=0.00657, epoch=14, loss=0.237, fake_loss=0.252, real_loss=0.222]\n",
      " 17%|██████▌                                | 1520/9120 [06:18<31:22,  4.04it/s]"
     ]
    }
   ],
   "source": [
    "!python -u -m torch.distributed.launch --nproc_per_node=2 --master_port 9901 training/pipelines/train_classifier.py \\\n",
    " --distributed --config configs/475L2.json --freeze-epochs 0 --test_every 1 --opt-level O1 --label-smoothing 0.01 --fold 0 --folds-csv train_folds.csv --val-folds-csv val_folds.csv --seed 888 --val-dir ../dfdc_train_all/dfdc_test --data-dir ../dfdc_train_all/dfdc_train --prefix 475L2_ > logs/475L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"training/pipelines/train_classifier.py\", line 365, in <module>\n",
      "    main()\n",
      "  File \"training/pipelines/train_classifier.py\", line 153, in main\n",
      "    normalize=conf.get(\"normalize\", None))\n",
      "  File \"/dataset/workspace/training/datasets/classifier_dataset.py\", line 247, in __init__\n",
      "    self.df = pd.read_csv(self.folds_csv)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\", line 686, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\", line 435, in _read\n",
      "    filepath_or_buffer, encoding, compression\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\", line 243, in get_filepath_or_buffer\n",
      "    raise ValueError(msg)\n",
      "ValueError: Invalid file path or buffer object type: <class 'NoneType'>\n",
      "Traceback (most recent call last):\n",
      "  File \"training/pipelines/train_classifier.py\", line 365, in <module>\n",
      "    main()\n",
      "  File \"training/pipelines/train_classifier.py\", line 153, in main\n",
      "    normalize=conf.get(\"normalize\", None))\n",
      "  File \"/dataset/workspace/training/datasets/classifier_dataset.py\", line 247, in __init__\n",
      "    self.df = pd.read_csv(self.folds_csv)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\", line 686, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\", line 435, in _read\n",
      "    filepath_or_buffer, encoding, compression\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\", line 243, in get_filepath_or_buffer\n",
      "    raise ValueError(msg)\n",
      "ValueError: Invalid file path or buffer object type: <class 'NoneType'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py\", line 263, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launch.py\", line 259, in main\n",
      "    cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'training/pipelines/train_classifier.py', '--local_rank=1', '--distributed', '--config', 'configs/b7.json', '--freeze-epochs', '0', '--test_every', '1', '--opt-level', 'O1', '--label-smoothing', '0.01', '--folds-csv', 'folds.csv', '--fold', '0', '--seed', '555', '--data-dir', '../dfdc_train_all', '--prefix', 'b7_555_']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!python -u -m torch.distributed.launch --nproc_per_node=2 --master_port 9901 training/pipelines/train_classifier.py \\\n",
    " --distributed --config configs/b7.json --freeze-epochs 0 --test_every 1 --opt-level O1 --label-smoothing 0.01 --folds-csv folds.csv  --fold 0 --seed 555 --data-dir ../dfdc_train_all --prefix b7_555_ > logs/b7_555\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u -m torch.distributed.launch --nproc_per_node=2 --master_port 9901 training/pipelines/train_classifier.py \\\n",
    " --distributed --config configs/b7.json --freeze-epochs 0 --test_every 1 --opt-level O1 --label-smoothing 0.01 --folds-csv folds.csv  --fold 0 --seed 777 --data-dir ../dfdc_train_all --prefix b7_777_ > logs/b7_777\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
